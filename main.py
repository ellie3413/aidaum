import streamlit as st
# Streamlit ì„¤ì •ì„ ê°€ì¥ ë¨¼ì € í˜¸ì¶œí•´ì•¼ í•¨
st.set_page_config(page_title="AI ë„êµ¬ ì¶”ì²œ", page_icon="ğŸŒŸ", layout="wide")

import pandas as pd
import json
import matplotlib.pyplot as plt
import os
import re
from dotenv import load_dotenv
from survey import questions, reset_survey, run_survey
from langchain.chains import RetrievalQA
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAI
from langchain_community.document_loaders import TextLoader  
from langchain.chains.question_answering import load_qa_chain
from user_type import determine_user_type, get_user_type_description


#========== í™˜ê²½ ë³€ìˆ˜ ë¡œë”© ==========
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
os.environ["OPENAI_API_KEY"] = api_key

# OpenAI API í‚¤ê°€ ìœ íš¨í•œì§€ ê°„ë‹¨íˆ í…ŒìŠ¤íŠ¸
try:
    # OpenAI ê°ì²´ ìƒì„± í…ŒìŠ¤íŠ¸
    test_llm = OpenAI(temperature=0.1)
except Exception as e:
    st.error(f"âŒ OpenAI API í‚¤ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()

#========== í•¨ìˆ˜ ì •ì˜ ==========
def load_json_data():
    """JSON íŒŒì¼ì—ì„œ AI ë„êµ¬ ë°ì´í„° ë¡œë“œ"""
    try:
        with open("tools.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        st.error(f"âŒ JSON íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def filter_tools_by_difficulty(tools, difficulty_level):
    """ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ AI ë„êµ¬ í•„í„°ë§"""
    if difficulty_level == "ëª¨ë“  ë‚œì´ë„":
        return tools
    
    difficulty_map = {
        "ì‰¬ì›€": "low", 
        "ì¤‘ê°„": "medium", 
        "ì–´ë ¤ì›€": "hard"
    }
    
    target_difficulty = difficulty_map.get(difficulty_level)
    
    filtered = []
    for tool in tools:
        # None ë‚œì´ë„ëŠ” ì¤‘ê°„ ë‚œì´ë„ë¡œ ê°„ì£¼
        if tool.get("difficulty") is None and target_difficulty == "medium":
            filtered.append(tool)
        elif tool.get("difficulty") == target_difficulty:
            filtered.append(tool)
    return filtered

def filter_tools_by_category(tools, category):
    """ì¹´í…Œê³ ë¦¬ ê¸°ì¤€ìœ¼ë¡œ AI ë„êµ¬ í•„í„°ë§"""
    if category == "ëª¨ë“  ì¹´í…Œê³ ë¦¬":
        return tools
    
    return [tool for tool in tools if tool.get("category") == category]

def filter_tools_by_search(tools, search_term):
    """ê²€ìƒ‰ì–´ ê¸°ì¤€ìœ¼ë¡œ AI ë„êµ¬ í•„í„°ë§"""
    if not search_term:
        return tools
    
    return [tool for tool in tools if search_term.lower() in tool.get("name", "").lower() or 
            (tool.get("description") and search_term.lower() in tool.get("description", "").lower())]

def get_tool_details(tool_name, tools_data):
    """ë„êµ¬ ì´ë¦„ìœ¼ë¡œ ì„¸ë¶€ ì •ë³´ ê²€ìƒ‰"""
    for tool in tools_data:
        if tool["name"].lower() == tool_name.lower():
            return tool
    return None

def find_best_matching_tool(tool_name, tools_data):
    """ê°€ì¥ ìœ ì‚¬í•œ ë„êµ¬ ì´ë¦„ ì°¾ê¸°"""
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë„êµ¬ ë¨¼ì € í™•ì¸
    for tool in tools_data:
        if tool["name"].lower() == tool_name.lower():
            return tool
    
    # ë¶€ë¶„ ì¼ì¹˜í•˜ëŠ” ë„êµ¬ í™•ì¸
    for tool in tools_data:
        if tool_name.lower() in tool["name"].lower() or tool["name"].lower() in tool_name.lower():
            return tool
    
    return None

def save_user_feedback(tool_name, rating, feedback_text):
    """ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥"""
    feedback_data = {
        "tool": tool_name,
        "rating": rating,
        "feedback": feedback_text,
        "responses": st.session_state.responses
    }
    
    # í”¼ë“œë°± íŒŒì¼ ì €ì¥
    try:
        if os.path.exists("user_feedback.json"):
            with open("user_feedback.json", "r", encoding="utf-8") as f:
                existing_data = json.load(f)
            existing_data.append(feedback_data)
            with open("user_feedback.json", "w", encoding="utf-8") as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
        else:
            with open("user_feedback.json", "w", encoding="utf-8") as f:
                json.dump([feedback_data], f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def visualize_category_distribution(tools_data):
    """ì¹´í…Œê³ ë¦¬ë³„ AI ë„êµ¬ ë¶„í¬ ì‹œê°í™”"""
    categories = {}
    for tool in tools_data:
        category = tool.get("category", "ê¸°íƒ€")
        if category in categories:
            categories[category] += 1
        else:
            categories[category] = 1
    
    # ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ
    sorted_categories = dict(sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10])
    
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(sorted_categories.keys(), sorted_categories.values(), color='skyblue')
    
    # ê°’ ë ˆì´ë¸” í‘œì‹œ
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{height}',
                ha='center', va='bottom', fontsize=9)
    
    plt.xticks(rotation=45, ha='right')
    plt.title('AI ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ìƒìœ„ 10ê°œ)')
    plt.tight_layout()
    return fig

def recommend_tools_by_criteria(tools_data, user_responses, max_recommendations=3):
    """ì‚¬ìš©ì ì‘ë‹µ ê¸°ë°˜ìœ¼ë¡œ AI ë„êµ¬ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ì²œ"""
    if not tools_data:
        return []
    
    # ì ìˆ˜ ì´ˆê¸°í™”
    for tool in tools_data:
        tool['score'] = 0
        
    # 1. ë‚œì´ë„ ê¸°ì¤€ ì ìˆ˜í™” (ì‚¬ìš©ì ì„ í˜¸ ë‚œì´ë„ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
    difficulty_map = {
        "ì‰¬ì›€ (ì´ˆë³´ìë„ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬)": "low",
        "ì¤‘ê°„ (ê¸°ë³¸ì ì¸ ì§€ì‹ì´ í•„ìš”í•œ ë„êµ¬)": "medium", 
        "ì–´ë ¤ì›€ (ì „ë¬¸ì ì¸ ì§€ì‹ì´ í•„ìš”í•œ ê³ ê¸‰ ë„êµ¬)": "hard",
        "ë‚œì´ë„ë³´ë‹¤ëŠ” ê¸°ëŠ¥ ì¤‘ì‹¬ìœ¼ë¡œ ì„ íƒí•˜ê³  ì‹¶ìŒ": None
    }
    
    preferred_difficulty = difficulty_map.get(
        user_responses.get('preferred_difficulty', "ë‚œì´ë„ë³´ë‹¤ëŠ” ê¸°ëŠ¥ ì¤‘ì‹¬ìœ¼ë¡œ ì„ íƒí•˜ê³  ì‹¶ìŒ")
    )
    
    # ë‚œì´ë„ ì ìˆ˜ ê³„ì‚°
    if preferred_difficulty:
        for tool in tools_data:
            if tool.get('difficulty') == preferred_difficulty:
                tool['score'] += 5
            # None ë‚œì´ë„ëŠ” mediumìœ¼ë¡œ ê°„ì£¼
            elif tool.get('difficulty') is None and preferred_difficulty == "medium":
                tool['score'] += 4
    
    # 2. AI
    # 2. AI ì§€ì‹ ìˆ˜ì¤€ì— ë”°ë¥¸ ë‚œì´ë„ ì¡°ì •
    knowledge_level = user_responses.get('ai_knowledge', '')
    if knowledge_level in ['ì „í˜€ ëª¨ë¥¸ë‹¤', 'ì´ë¦„ë§Œ ë“¤ì–´ë´¤ë‹¤']:
        # ì´ˆë³´ìëŠ” ì‰¬ìš´ ë„êµ¬ ì„ í˜¸
        for tool in tools_data:
            if tool.get('difficulty') == 'low':
                tool['score'] += 3
    elif knowledge_level in ['AI ëª¨ë¸ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ ë‹¤ë¤„ë³¸ ì  ìˆë‹¤']:
        # ì „ë¬¸ê°€ëŠ” ì–´ë ¤ìš´ ë„êµ¬ ì„ í˜¸
        for tool in tools_data:
            if tool.get('difficulty') == 'hard':
                tool['score'] += 3
    
    # 3. ê´€ì‹¬ ë¶„ì•¼ ê¸°ë°˜ ì ìˆ˜í™”
    interests = user_responses.get('tool_interest', [])
    interest_category_map = {
        "í…ìŠ¤íŠ¸ ìƒì„±": ["AI Assistants (Chatbots)", "Writing", "Grammar and Writing Improvement"],
        "ì´ë¯¸ì§€ ìƒì„±": ["Image Generation", "Graphic Design"],
        "ì˜ìƒ/ìŒì„± í•©ì„±": ["Video Generation and Editing", "Voice Generation", "Music Generation"],
        "ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”": ["Research"],
        "ì—…ë¬´ ìë™í™”": ["Project Management", "Scheduling", "Email"],
        "ê²€ìƒ‰ ë° ì§€ì‹ ê´€ë¦¬": ["Search Engines", "Knowledge Management"],
        "ì½”ë“œ ìƒì„± ë° ê°œë°œ ì§€ì›": ["App Builders & Coding"],
        "ë²ˆì—­ ë° ì–¸ì–´ í•™ìŠµ": ["Grammar and Writing Improvement"],
        "ê¸°íƒ€": []
    }
    
    for interest in interests:
        matching_categories = interest_category_map.get(interest, [])
        for tool in tools_data:
            if tool.get('category') in matching_categories:
                tool['score'] += 4
    
    # 4. íŠ¹ì • ëª©ì  ê¸°ë°˜ ì ìˆ˜í™”
    purposes = user_responses.get('specific_purpose', [])
    purpose_category_map = {
        "ë¬¸ì„œ ì‘ì„± ë° í¸ì§‘": ["Writing", "Grammar and Writing Improvement"],
        "ì´ë¯¸ì§€/ì˜ìƒ ì œì‘": ["Image Generation", "Video Generation and Editing"],
        "ë°ì´í„° ë¶„ì„": ["Research"],
        "í”„ë¡œê·¸ë˜ë° ë° ê°œë°œ": ["App Builders & Coding"],
        "ë§ˆì¼€íŒ… ë° í™ë³´": ["Marketing", "Social Media Management"],
        "êµìœ¡ ë° í•™ìŠµ": ["Knowledge Management"],
        "ì—…ë¬´ ìë™í™”": ["Project Management", "Scheduling", "Email"],
        "ê³ ê° ì„œë¹„ìŠ¤": ["Customer Service"],
        "ì—°êµ¬ ë° ë…¼ë¬¸ ì‘ì„±": ["Research", "Writing"],
        "ê¸°íƒ€": []
    }
    
    for purpose in purposes:
        matching_categories = purpose_category_map.get(purpose, [])
        for tool in tools_data:
            if tool.get('category') in matching_categories:
                tool['score'] += 4
    
    # 5. ì§ì—… ê¸°ë°˜ ì ìˆ˜í™” (ì¶”ê°€ë¨)
    job = user_responses.get('job', '')
    job_category_map = {
        "í•™ìƒ": ["Writing", "Research", "Grammar and Writing Improvement", "Knowledge Management"],
        "ê°œë°œì/IT ì¢…ì‚¬ì": ["App Builders & Coding", "AI Assistants (Chatbots)"],
        "êµìœ¡ì/ì—°êµ¬ì›": ["Research", "Knowledge Management", "Presentations", "Writing"],
        "ë””ìì´ë„ˆ/ì°½ì‘ì": ["Image Generation", "Video Generation and Editing", "Graphic Design", "Music Generation"],
        "ë§ˆì¼€í„°/í™ë³´": ["Social Media Management", "Marketing", "Writing", "Image Generation"],
        "ì‚¬ë¬´ì§": ["Email", "Project Management", "Scheduling", "Writing"],
        "ê²½ì˜/ê´€ë¦¬ì": ["Project Management", "Knowledge Management", "Presentations"],
        "ì°½ì—…ê°€/í”„ë¦¬ëœì„œ": ["Marketing", "Social Media Management", "Email", "Customer Service"],
        "ì˜ë£Œ/ê±´ê°• ì¢…ì‚¬ì": ["Research", "Knowledge Management"],
        "ë²•ë¥ /ê¸ˆìœµ ì „ë¬¸ê°€": ["Research", "Grammar and Writing Improvement", "Writing"],
        "ê¸°íƒ€": []
    }
    
    if job:
        matching_categories = job_category_map.get(job, [])
        for tool in tools_data:
            if tool.get('category') in matching_categories:
                tool['score'] += 5  # ì§ì—… ê´€ë ¨ì„±ì´ ë†’ì€ ë„êµ¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    
    # ë„êµ¬ ì„¤ëª…ì´ ìˆëŠ” ë„êµ¬ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
    for tool in tools_data:
        if tool.get('description') and len(str(tool.get('description'))) > 10:
            tool['score'] += 1
    
    # ìµœì¢… ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ ì¶”ì²œ
    sorted_tools = sorted(tools_data, key=lambda x: x.get('score', 0), reverse=True)
    
    # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì‰¬ìš´ ë„êµ¬ê°€ í¬í•¨ë˜ë„ë¡ ë³´ì¥ (ì´ˆë³´ìë¥¼ ìœ„í•œ ë°°ë ¤)
    recommended = []
    has_easy_tool = False
    
    # ìƒìœ„ ë„êµ¬ë“¤ ì¤‘ì—ì„œ ì„ íƒ
    for tool in sorted_tools:
        if len(recommended) < max_recommendations:
            recommended.append(tool)
            if tool.get('difficulty') == 'low':
                has_easy_tool = True
        elif not has_easy_tool and tool.get('difficulty') == 'low':
            # ì‰¬ìš´ ë„êµ¬ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë„êµ¬ë¥¼ ì‰¬ìš´ ë„êµ¬ë¡œ êµì²´
            recommended[-1] = tool
            has_easy_tool = True
            break
    
    return recommended

def translate_difficulty(difficulty):
    """ë‚œì´ë„ ì˜ì–´ í‘œí˜„ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
    if difficulty == "low":
        return "ì‰¬ì›€"
    elif difficulty == "medium":
        return "ì¤‘ê°„"
    elif difficulty == "hard":
        return "ì–´ë ¤ì›€"
    return "ì¤‘ê°„"  # ê¸°ë³¸ê°’

def add_korean_description(tools):
    """ì˜ì–´ ì„¤ëª…ì´ ìˆëŠ” ë„êµ¬ì— í•œêµ­ì–´ ì„¤ëª… ì¶”ê°€"""
    korean_descriptions = {
        "ChatGPT": "ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ëŒ€í™”ê°€ ê°€ëŠ¥í•œ OpenAIì˜ ëŒ€í‘œì ì¸ AI ì±—ë´‡ìœ¼ë¡œ, ì½”ë”©, ê¸€ì“°ê¸°, ì§ˆë¬¸ ì‘ë‹µ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "Claude": "Anthropicì—ì„œ ê°œë°œí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ, ì¹œì ˆí•˜ê³  ì •í™•í•œ ì‘ë‹µê³¼ íŠ¹íˆ ì½”ë”©ì— ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
        "Gemini": "Googleì—ì„œ ê°œë°œí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ êµ¬ê¸€ ìƒíƒœê³„ì™€ ë†’ì€ í†µí•©ì„±ì„ ê°€ì§€ê³  ìˆìœ¼ë©° ê²€ìƒ‰ê³¼ ì •ë³´ ìš”ì•½ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤.",
        "Midjourney": "í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” AI ë„êµ¬ë¡œ, ì˜ˆìˆ ì  í‘œí˜„ê³¼ ì°½ì˜ì ì¸ ì‹œê°í™”ì— íƒì›”í•©ë‹ˆë‹¤.",
        "Perplexity": "ë‹¤ì–‘í•œ ì •ë³´ ì†ŒìŠ¤ë¥¼ í™œìš©í•´ ê¹Šì´ ìˆëŠ” ê²€ìƒ‰ê³¼ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤.",
        "Grammarly": "í…ìŠ¤íŠ¸ ì‘ì„± ì‹œ ë¬¸ë²•, ë§ì¶¤ë²•, ë¬¸ì²´ë¥¼ ìë™ìœ¼ë¡œ êµì •í•´ì£¼ëŠ” AI ê¸€ì“°ê¸° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.",
        "Canva Magic Studio": "ì†ì‰¬ìš´ ë””ìì¸ ì œì‘ì„ ìœ„í•œ AI ê¸°ëŠ¥ì´ ê°•í™”ëœ ê·¸ë˜í”½ ë””ìì¸ í”Œë«í¼ì…ë‹ˆë‹¤.",
        "Cursor": "AI ê¸°ë°˜ ì½”ë“œ ì‘ì„±ê³¼ í¸ì§‘ì„ ë„ì™€ì£¼ëŠ” ê°œë°œì ë„êµ¬ë¡œ, ì½”ë”© ìƒì‚°ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
    }
    
    for tool in tools:
        if tool.get("name") in korean_descriptions and (tool.get("description") is None or "Korean" not in tool.get("lang", [])):
            tool["korean_description"] = korean_descriptions[tool.get("name")]
    
    return tools

#========== Streamlit UI ==========
st.title("ì—ì´ì•„ì´ë‹¤ì›€")
st.write("ì„¤ë¬¸ì¡°ì‚¬ë¥¼ ì™„ë£Œí•˜ì‹œë©´, ë‹¹ì‹ ì—ê²Œ ë§ëŠ” AI ë„êµ¬ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")

#========== ì„¤ë¬¸ í™”ë©´ ==========
run_survey()

#========== ì„¤ë¬¸ ì™„ë£Œ ì—¬ë¶€ í™•ì¸ ==========
if not st.session_state.get("survey_complete", False):
    st.stop()

responses = st.session_state.responses

#========== tools.txt ë° JSON ë°ì´í„° ë¡œë“œ ==========

loader = TextLoader("tools.txt", encoding="utf-8") 
pages = loader.load_and_split()

# JSON ë°ì´í„° ë¡œë“œ
tools_data = load_json_data()

#========== ì‚¬ìš©ì ì„ í˜¸ë„ì— ë§ëŠ” ê²€ìƒ‰ ë§¤ê°œë³€ìˆ˜ ê²°ì • ==========
search_kwargs = {"k": 5}  # ê¸°ë³¸ê°’

# AI ì§€ì‹ ìˆ˜ì¤€ì— ë”°ë¼ ê²€ìƒ‰ ê¹Šì´ ì¡°ì •
if responses.get('ai_knowledge') in ['ì „í˜€ ëª¨ë¥¸ë‹¤', 'ì´ë¦„ë§Œ ë“¤ì–´ë´¤ë‹¤']:
    search_kwargs["k"] = 3  # ì´ˆë³´ìëŠ” ë” ê¸°ë³¸ì ì¸ ë‚´ìš©ë§Œ ê²€ìƒ‰
elif responses.get('ai_knowledge') in ['AI ëª¨ë¸ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ ë‹¤ë¤„ë³¸ ì  ìˆë‹¤']:
    search_kwargs["k"] = 7  # ì „ë¬¸ê°€ëŠ” ë” ê¹Šì€ ê²€ìƒ‰

#========== AI ìœ í˜• ì¶”ì²œ ==========

st.markdown("### ğŸ§© ë‹¹ì‹ ì˜ AI ìœ í˜•ì€?")

# ì‚¬ìš©ì ìœ í˜• ê²°ì •
user_type = determine_user_type(responses)
user_type_info = get_user_type_description(user_type)

# ìœ í˜• ì •ë³´ í‘œì‹œ
st.markdown(f"## {user_type_info['title']}")
st.markdown(user_type_info['description'])

# ìœ í˜• ì„¸ë¶€ ì •ë³´
col1, col2 = st.columns(2)
with col1:
    st.markdown("#### ğŸ’ª ê°•ì ")
    st.markdown(user_type_info['strengths'])
    
with col2:
    st.markdown("#### ğŸš€ ì¶”ì²œ ì ‘ê·¼ë²•")
    st.markdown(user_type_info['recommended_approach'])

st.markdown("---")


#========== ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ë„êµ¬ ì¶”ì²œ ==========
st.markdown("### ğŸ” ë‹¹ì‹ ì„ ìœ„í•œ AI ë„êµ¬ ì¶”ì²œ")

# í•œêµ­ì–´ ì„¤ëª… ì¶”ê°€
tools_data = add_korean_description(tools_data)

# ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì¶”ì²œ
with st.spinner("ì¶”ì²œ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
    recommended_tools = recommend_tools_by_criteria(tools_data, responses, max_recommendations=3)

# ì¶”ì²œ ê²°ê³¼ í‘œì‹œ
if recommended_tools:
    st.success(f"âœ… ì„¤ë¬¸ ì‘ë‹µì— ê¸°ë°˜í•œ ë§ì¶¤í˜• AI ë„êµ¬ ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.markdown(f"**{user_type}** ìœ í˜•ì¸ ë‹¹ì‹ ì„ ìœ„í•œ ë§ì¶¤í˜• AI ë„êµ¬ì…ë‹ˆë‹¤. ì´ ë„êµ¬ë“¤ì€ ë‹¹ì‹ ì˜ ê´€ì‹¬ì‚¬, ëª©ì , ì§ì—…ì„ ê³ ë ¤í•˜ì—¬ íŠ¹ë³„íˆ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")


    
    # 3ê°œì˜ ì—´ë¡œ ì¶”ì²œ ë„êµ¬ í‘œì‹œ
    cols = st.columns(len(recommended_tools))
    
    for i, tool in enumerate(recommended_tools):
        with cols[i]:
            st.markdown(f"### {i+1}. {tool.get('name')}")
            st.markdown(f"**ì¹´í…Œê³ ë¦¬**: {tool.get('category', 'ì •ë³´ ì—†ìŒ')}")
            st.markdown(f"**ë‚œì´ë„**: {translate_difficulty(tool.get('difficulty', 'medium'))}")
            
            # í•œêµ­ì–´ ì„¤ëª… ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ì¡´ ì„¤ëª… ì‚¬ìš©
            if tool.get("korean_description"):
                st.markdown(f"**ì„¤ëª…**: {tool.get('korean_description')}")
            elif tool.get("description"):
                st.markdown(f"**ì„¤ëª…**: {tool.get('description')}")
            else:
                st.markdown("**ì„¤ëª…**: ìƒì„¸ ì„¤ëª… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë„êµ¬ë³„ ìƒì„¸ ì„¤ëª… ë²„íŠ¼
            if st.button(f"{tool.get('name')} ìì„¸íˆ ë³´ê¸°", key=f"detail_{i}"):
                # ì„¸ì…˜ ìƒíƒœì— ì„ íƒëœ ë„êµ¬ ì €ì¥
                st.session_state.selected_tool = tool.get('name')
                st.rerun()
else:
    st.warning("âš ï¸ ì¶”ì²œ ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ë¬¸ ì‘ë‹µì„ ì‹œë„í•´ ë³´ì„¸ìš”.")

# ì„ íƒëœ ë„êµ¬ ìƒì„¸ ì •ë³´ í‘œì‹œ
if hasattr(st.session_state, 'selected_tool') and st.session_state.selected_tool:
    tool_name = st.session_state.selected_tool
    st.markdown(f"## {tool_name} ìƒì„¸ ì •ë³´")
    
    # íˆ´ ì •ë³´ ì°¾ê¸°
    tool_info = get_tool_details(tool_name, tools_data)
    
    if tool_info:
        st.markdown(f"**ì¹´í…Œê³ ë¦¬**: {tool_info.get('category', 'ì •ë³´ ì—†ìŒ')}")
        st.markdown(f"**ë‚œì´ë„**: {translate_difficulty(tool_info.get('difficulty', 'medium'))}")
        
        # í•œêµ­ì–´ ì„¤ëª… ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ì¡´ ì„¤ëª… ì‚¬ìš©
        if tool_info.get("korean_description"):
            st.markdown(f"**ì„¤ëª…**: {tool_info.get('korean_description')}")
        elif tool_info.get("description"):
            st.markdown(f"**ì„¤ëª…**: {tool_info.get('description')}")
        else:
            st.markdown("**ì„¤ëª…**: ìƒì„¸ ì„¤ëª… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # tools.txtì—ì„œ í•´ë‹¹ ë„êµ¬ ê²€ìƒ‰
        embeddings = OpenAIEmbeddings()
        try:
            vectorstore = FAISS.from_texts(texts=[page.page_content for page in pages], embedding=embeddings)
            query = f"{tool_name}ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ì™€ ì‚¬ìš© ë°©ë²•"
            docs = vectorstore.similarity_search(query, k=2)
            
            if docs:
                st.markdown("### ğŸ“š ì¶”ê°€ ì •ë³´")
                for doc in docs:
                    st.markdown(doc.page_content)
        except Exception as e:
            st.error(f"ë„êµ¬ ìƒì„¸ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.error(f"{tool_name}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìƒì„¸ë³´ê¸° ë‹«ê¸°
    if st.button("ìƒì„¸ ì •ë³´ ë‹«ê¸°"):
        del st.session_state.selected_tool
        st.rerun()

st.markdown("---")

#========== ì ìˆ˜í‘œ ==========
if recommended_tools:
    with st.expander("ğŸ¤– ë§ì¶¤í˜• ë„êµ¬ ì„ ì • ê·¼ê±°(ì ìˆ˜í‘œ)", expanded=False):
        st.markdown("#### ì¶”ì²œ ì ìˆ˜ ë¶„í¬")
        score_fig, ax = plt.subplots(figsize=(8, 4))
        tool_names = [tool.get('name') for tool in recommended_tools]
        scores = [tool.get('score', 0) for tool in recommended_tools]
        
        bars = ax.barh(tool_names, scores, color=['#2E86C1', '#3498DB', '#85C1E9'])

        # ê°’ í‘œì‹œ
        for i, (score, bar) in enumerate(zip(scores, bars)):
            ax.text(score + 0.5, i, f"{score}", ha='left', va='center')
        
        plt.xlabel('your score')
        plt.tight_layout()
        st.pyplot(score_fig)


#========== ë‚œì´ë„ í•„í„° ë° ì„¸ë¶€ ì •ë³´ ==========
st.markdown("---")
st.markdown("### ğŸ” AI ë„êµ¬ ë°ì´í„°ë² ì´ìŠ¤ íƒìƒ‰")

if tools_data:
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # ë‚œì´ë„ë³„ í•„í„°ë§
        difficulty_options = ["ëª¨ë“  ë‚œì´ë„", "ì‰¬ì›€", "ì¤‘ê°„", "ì–´ë ¤ì›€"]
        selected_difficulty = st.selectbox("ë‚œì´ë„ë³„ í•„í„°ë§", difficulty_options)
    
    with col2:
        # ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§
        categories = ["ëª¨ë“  ì¹´í…Œê³ ë¦¬"] + sorted(list(set([tool.get("category", "ê¸°íƒ€") for tool in tools_data if tool.get("category")])))
        selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§", categories)
    
    with col3:
        # ê²€ìƒ‰ì–´ í•„í„°ë§
        search_term = st.text_input("ğŸ” ë„êµ¬ ì´ë¦„ ë˜ëŠ” ì„¤ëª… ê²€ìƒ‰")
    
    # í•„í„°ë§ ì ìš©
    filtered_tools = filter_tools_by_difficulty(tools_data, selected_difficulty)
    filtered_tools = filter_tools_by_category(filtered_tools, selected_category)
    filtered_tools = filter_tools_by_search(filtered_tools, search_term)
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë„êµ¬ ë¶„í¬ ì‹œê°í™”
    st.markdown("### ğŸ“Š AI ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë¶„í¬")
    fig = visualize_category_distribution(tools_data)
    st.pyplot(fig)
    
    # í•„í„°ë§ëœ ë„êµ¬ ë¦¬ìŠ¤íŠ¸
    st.markdown("### ğŸ“‹ í•„í„°ë§ëœ ë„êµ¬ ëª©ë¡")
    if filtered_tools:
        tool_df = pd.DataFrame([{
            "ì´ë¦„": tool.get("name", ""),
            "ì¹´í…Œê³ ë¦¬": tool.get("category", ""),
            "ë‚œì´ë„": translate_difficulty(tool.get("difficulty", "medium"))
        } for tool in filtered_tools])
        
        st.dataframe(tool_df, use_container_width=True)
        
        # ë„êµ¬ ìƒì„¸ ì •ë³´ í™•ì¸
        selected_tool_name = st.selectbox("ìƒì„¸ ì •ë³´ë¥¼ ë³¼ ë„êµ¬ ì„ íƒ", ["ì„ íƒí•˜ì„¸ìš”"] + tool_df["ì´ë¦„"].tolist())
        
        if selected_tool_name != "ì„ íƒí•˜ì„¸ìš”":
            tool_info = get_tool_details(selected_tool_name, tools_data)
            if tool_info:
                st.markdown(f"### {selected_tool_name} ìƒì„¸ ì •ë³´")
                st.markdown(f"**ì¹´í…Œê³ ë¦¬**: {tool_info.get('category', 'ì •ë³´ ì—†ìŒ')}")
                st.markdown(f"**ë‚œì´ë„**: {translate_difficulty(tool_info.get('difficulty', 'medium'))}")
                
                # í•œêµ­ì–´ ì„¤ëª… ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ì¡´ ì„¤ëª… ì‚¬ìš©
                if tool_info.get("korean_description"):
                    st.markdown(f"**ì„¤ëª…**: {tool_info.get('korean_description')}")
                elif tool_info.get("description"):
                    st.markdown(f"**ì„¤ëª…**: {tool_info.get('description')}")
                else:
                    st.markdown("**ì„¤ëª…**: ìƒì„¸ ì„¤ëª… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

#========== ì‚¬ìš©ì í”¼ë“œë°± ==========
st.markdown("---")
st.markdown("### ğŸ“ ì¶”ì²œ í”¼ë“œë°±")
feedback_tool = st.text_input("í”¼ë“œë°±ì„ ë‚¨ê¸¸ ë„êµ¬ ì´ë¦„")

if feedback_tool:
    rating = st.slider("ë§Œì¡±ë„ í‰ê°€", 1, 5, 3)
    feedback_text = st.text_area("ìƒì„¸ í”¼ë“œë°± (ì„ íƒì‚¬í•­)")
    
    if st.button("í”¼ë“œë°± ì œì¶œ"):
        if save_user_feedback(feedback_tool, rating, feedback_text):
            st.success("í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
        else:
            st.error("í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

#========== í•™ìŠµ ë¦¬ì†ŒìŠ¤ ì¶”ì²œ ==========
st.markdown("---")
st.markdown("### ğŸ“š ì¶”ì²œ í•™ìŠµ ë¦¬ì†ŒìŠ¤")

learning_resources = {
    "ì´ˆë³´ì": [
        "AI ê¸°ì´ˆ ê°œë… ì´í•´í•˜ê¸° - ì‰¬ìš´ ì‹œì‘ ê°€ì´ë“œ",
        "ì²˜ìŒ ë§Œë‚˜ëŠ” ChatGPT - ê¸°ë³¸ ì‚¬ìš©ë²•",
        "AI ë„êµ¬ ì…ë¬¸ìë¥¼ ìœ„í•œ ë‹¨ê³„ë³„ í•™ìŠµ ê²½ë¡œ"
    ],
    "ì¤‘ê¸‰ì": [
        "ì‹¤ë¬´ì— ë°”ë¡œ ì ìš©í•˜ëŠ” AI ë„êµ¬ í™œìš©ë²•",
        "ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ AI ëª¨ë¸ í™œìš©í•˜ê¸°",
        "ì—…ë¬´ ìë™í™”ë¥¼ ìœ„í•œ AI ì›Œí¬í”Œë¡œìš° êµ¬ì¶•"
    ],
    "ì „ë¬¸ê°€": [
        "ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•",
        "AI ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•",
        "RAG(Retrieval Augmented Generation) ê³ ê¸‰ í™œìš©ë²•"
    ]
}

# ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ë¦¬ì†ŒìŠ¤ í‘œì‹œ
user_level = "ì´ˆë³´ì"
if responses.get('ai_knowledge') in ['ê¸°ë³¸ ê°œë…ì€ ì•Œê³  ìˆë‹¤', 'ì‹¤ì œë¡œ í™œìš©í•´ë³¸ ê²½í—˜ì´ ìˆë‹¤']:
    user_level = "ì¤‘ê¸‰ì"
elif responses.get('ai_knowledge') in ['AI ëª¨ë¸ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ ë‹¤ë¤„ë³¸ ì  ìˆë‹¤']:
    user_level = "ì „ë¬¸ê°€"

st.info(f"ğŸ“š ë‹¹ì‹ ì˜ ìˆ˜ì¤€({user_level})ì— ë§ëŠ” í•™ìŠµ ë¦¬ì†ŒìŠ¤ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤:")
for resource in learning_resources[user_level]:
    st.markdown(f"- {resource}")

st.button("ğŸ”„ ì„¤ë¬¸ ë‹¤ì‹œ í•˜ê¸°", on_click=reset_survey)