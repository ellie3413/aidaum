# main.py

import streamlit as st
# Streamlit ì„¤ì •ì„ ê°€ì¥ ë¨¼ì € í˜¸ì¶œí•´ì•¼ í•¨
st.set_page_config(page_title="AI ë„êµ¬ ì¶”ì²œ", page_icon="ğŸŒŸ", layout="wide")

import pandas as pd
import json
import matplotlib.pyplot as plt
import os
import re
from dotenv import load_dotenv
from survey import questions, reset_survey, run_survey
from langchain.chains import RetrievalQA
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAI
from langchain_community.document_loaders import TextLoader  
from langchain.chains.question_answering import load_qa_chain

#========== í™˜ê²½ ë³€ìˆ˜ ë¡œë”© ==========
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
os.environ["OPENAI_API_KEY"] = api_key

# OpenAI API í‚¤ê°€ ìœ íš¨í•œì§€ ê°„ë‹¨íˆ í…ŒìŠ¤íŠ¸
try:
    # OpenAI ê°ì²´ ìƒì„± í…ŒìŠ¤íŠ¸
    test_llm = OpenAI(temperature=0.1)
except Exception as e:
    st.error(f"âŒ OpenAI API í‚¤ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()

#========== í•¨ìˆ˜ ì •ì˜ ==========
def load_json_data():
    """JSON íŒŒì¼ì—ì„œ AI ë„êµ¬ ë°ì´í„° ë¡œë“œ"""
    try:
        with open("ai_tools_detailed_with_difficulty.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        st.error(f"âŒ JSON íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def filter_tools_by_difficulty(tools, difficulty_level):
    """ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ AI ë„êµ¬ í•„í„°ë§"""
    if difficulty_level == "ëª¨ë“  ë‚œì´ë„":
        return tools
    
    filtered = []
    for tool in tools:
        # None ë‚œì´ë„ëŠ” ì¤‘ê°„ ë‚œì´ë„ë¡œ ê°„ì£¼
        if tool.get("difficulty") is None and difficulty_level == "ì¤‘ê°„":
            filtered.append(tool)
        elif tool.get("difficulty") == difficulty_level.lower():
            filtered.append(tool)
    return filtered

def get_tool_details(tool_name, tools_data):
    """ë„êµ¬ ì´ë¦„ìœ¼ë¡œ ì„¸ë¶€ ì •ë³´ ê²€ìƒ‰"""
    for tool in tools_data:
        if tool["name"].lower() == tool_name.lower():
            return tool
    return None

def save_user_feedback(tool_name, rating, feedback_text):
    """ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥"""
    feedback_data = {
        "tool": tool_name,
        "rating": rating,
        "feedback": feedback_text,
        "responses": st.session_state.responses
    }
    
    # í”¼ë“œë°± íŒŒì¼ ì €ì¥
    try:
        if os.path.exists("user_feedback.json"):
            with open("user_feedback.json", "r", encoding="utf-8") as f:
                existing_data = json.load(f)
            existing_data.append(feedback_data)
            with open("user_feedback.json", "w", encoding="utf-8") as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
        else:
            with open("user_feedback.json", "w", encoding="utf-8") as f:
                json.dump([feedback_data], f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def visualize_category_distribution(tools_data):
    """ì¹´í…Œê³ ë¦¬ë³„ AI ë„êµ¬ ë¶„í¬ ì‹œê°í™”"""
    categories = {}
    for tool in tools_data:
        category = tool.get("category", "ê¸°íƒ€")
        if category in categories:
            categories[category] += 1
        else:
            categories[category] = 1
    
    # ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ
    sorted_categories = dict(sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10])
    
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(sorted_categories.keys(), sorted_categories.values(), color='skyblue')
    
    # ê°’ ë ˆì´ë¸” í‘œì‹œ
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{height}',
                ha='center', va='bottom', fontsize=9)
    
    plt.xticks(rotation=45, ha='right')
    plt.title('AI ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ìƒìœ„ 10ê°œ)')
    plt.tight_layout()
    return fig

def extract_recommended_tools(answer_text):
    """AI ì¶”ì²œ ë‹µë³€ì—ì„œ ë„êµ¬ ì´ë¦„ ì¶”ì¶œ"""
    # ë„êµ¬ ì´ë¦„ ì¶”ì¶œ íŒ¨í„´ (": "ë‚˜ "- " ë’¤ì— ì˜¤ëŠ” ë‹¨ì–´ë‚˜ êµ¬ë¬¸)
    tool_patterns = [
        r'\*\*(.*?)\*\*',  # **Tool Name**
        r'ì´ë¦„:\s*(.*?)(?:\n|$)',  # ì´ë¦„: Tool Name
        r'ë„êµ¬ëª…:\s*(.*?)(?:\n|$)',  # ë„êµ¬ëª…: Tool Name
        r'^\d+\.\s*(.*?)(?::|$)',  # 1. Tool Name: ë˜ëŠ” 1. Tool Name
        r'^\-\s*(.*?)(?::|$)',  # - Tool Name: ë˜ëŠ” - Tool Name
    ]
    
    tools = []
    lines = answer_text.split('\n')
    
    for line in lines:
        for pattern in tool_patterns:
            matches = re.findall(pattern, line, re.MULTILINE)
            if matches:
                for match in matches:
                    # íŠ¹ìˆ˜ë¬¸ì ë° ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                    tool_name = match.strip(':,.()[]{}').strip()
                    if tool_name and len(tool_name) < 50:  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ë„êµ¬ëª…ì´ ì•„ë‹ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                        tools.append(tool_name)
    
    # ì¤‘ë³µ ì œê±° ë° ì •ì œ
    unique_tools = []
    for tool in tools:
        if tool not in unique_tools and not any(keyword in tool.lower() for keyword in ['ì´ë¦„', 'ë„êµ¬', 'ì¶”ì²œ', 'ê¸°ëŠ¥', 'ì¹´í…Œê³ ë¦¬']):
            unique_tools.append(tool)
    
    return unique_tools

def create_radar_chart(tools_data, recommended_tools):
    """ì¶”ì²œëœ ë„êµ¬ë“¤ì˜ ì¹´í…Œê³ ë¦¬ ë ˆì´ë” ì°¨íŠ¸ ìƒì„±"""
    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    all_categories = set()
    for tool in tools_data:
        if tool.get("category"):
            all_categories.add(tool.get("category"))
    
    categories = list(all_categories)[:8]  # ìƒìœ„ 8ê°œ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©
    
    # ì¶”ì²œ ë„êµ¬ë“¤ì˜ ì¹´í…Œê³ ë¦¬ ì¹´ìš´íŒ…
    category_counts = {category: 0 for category in categories}
    tool_categories = {}
    
    for tool_name in recommended_tools:
        for tool in tools_data:
            if tool["name"].lower() == tool_name.lower() and tool.get("category") in categories:
                category_counts[tool.get("category")] += 1
                if tool_name not in tool_categories:
                    tool_categories[tool_name] = tool.get("category")
    
    # ë ˆì´ë” ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
    values = [category_counts.get(category, 0) for category in categories]
    values.append(values[0])  # ë ˆì´ë” ì°¨íŠ¸ë¥¼ ë‹«ê¸° ìœ„í•´ ì²« ê°’ ë°˜ë³µ
    categories.append(categories[0])  # ì¶• ë ˆì´ë¸”ë„ ë§ˆì°¬ê°€ì§€ë¡œ ë°˜ë³µ
    
    # ë ˆì´ë” ì°¨íŠ¸ ìƒì„±
    angles = [n / float(len(categories)-1) * 2 * 3.14159 for n in range(len(categories))]
    
    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))
    ax.plot(angles, values, linewidth=2, linestyle='solid')
    ax.fill(angles, values, 'skyblue', alpha=0.4)
    
    # ì¶• ë ˆì´ë¸” ì„¤ì •
    plt.xticks(angles[:-1], categories[:-1])
    
    # ê°’ í‘œì‹œ
    for i, (angle, value) in enumerate(zip(angles[:-1], values[:-1])):
        if value > 0:
            ax.text(angle, value + 0.1, str(value), ha='center', va='center')
    
    plt.title('ì¶”ì²œëœ ë„êµ¬ë“¤ì˜ ì¹´í…Œê³ ë¦¬ ë¶„í¬')
    return fig, tool_categories

#========== Streamlit UI ==========
st.title("ğŸ¯ AI ë¦¬í„°ëŸ¬ì‹œ ê¸°ë°˜ AI ë„êµ¬ ì¶”ì²œ")
st.write("ì„¤ë¬¸ì¡°ì‚¬ë¥¼ ì™„ë£Œí•˜ì‹œë©´, ë‹¹ì‹ ì—ê²Œ ë§ëŠ” AI ë„êµ¬ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")

#========== ì„¤ë¬¸ í™”ë©´ ==========
run_survey()

#========== ì„¤ë¬¸ ì™„ë£Œ ì—¬ë¶€ í™•ì¸ ==========
if not st.session_state.get("survey_complete", False):
    st.stop()

responses = st.session_state.responses

#========== tools.txt ë° JSON ë°ì´í„° ë¡œë“œ ==========
with st.expander("ğŸ“¦ ë°ì´í„° ë¡œë“œ ìƒíƒœ", expanded=False):
    st.markdown("### ğŸ“– ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # tools.txt ë¡œë“œ
    try:
        loader = TextLoader("tools.txt", encoding="utf-8") 
        pages = loader.load_and_split()
        st.success("âœ… tools.txt ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        st.error("âŒ tools.txt íŒŒì¼ì´ í˜„ì¬ í´ë”ì— ì—†ìŠµë‹ˆë‹¤. í™•ì¸ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # JSON ë°ì´í„° ë¡œë“œ
    tools_data = load_json_data()
    if tools_data:
        st.success(f"âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(tools_data)}ê°œ ë„êµ¬ ì •ë³´)")
    else:
        st.warning("âš ï¸ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œë§Œ ì œê³µë©ë‹ˆë‹¤.")

#========== ì‚¬ìš©ì ì„ í˜¸ë„ì— ë§ëŠ” ê²€ìƒ‰ ë§¤ê°œë³€ìˆ˜ ê²°ì • ==========
search_kwargs = {"k": 5}  # ê¸°ë³¸ê°’

# AI ì§€ì‹ ìˆ˜ì¤€ì— ë”°ë¼ ê²€ìƒ‰ ê¹Šì´ ì¡°ì •
if responses.get('ai_knowledge') in ['ì „í˜€ ëª¨ë¥¸ë‹¤', 'ì´ë¦„ë§Œ ë“¤ì–´ë´¤ë‹¤']:
    search_kwargs["k"] = 3  # ì´ˆë³´ìëŠ” ë” ê¸°ë³¸ì ì¸ ë‚´ìš©ë§Œ ê²€ìƒ‰
elif responses.get('ai_knowledge') in ['AI ëª¨ë¸ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ ë‹¤ë¤„ë³¸ ì  ìˆë‹¤']:
    search_kwargs["k"] = 7  # ì „ë¬¸ê°€ëŠ” ë” ê¹Šì€ ê²€ìƒ‰

#========== RAG ê¸°ë°˜ ë„êµ¬ ì¶”ì²œ ==========
embeddings = OpenAIEmbeddings()

# ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
texts = [page.page_content for page in pages]
metadatas = [page.metadata for page in pages]

# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
try:
    vectorstore = FAISS.from_texts(texts=texts, embedding=embeddings, metadatas=metadatas)
    st.success("âœ… ë²¡í„°ìŠ¤í† ì–´ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"âŒ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()

# ìµœì‹  ë²„ì „ì˜ Langchainì— ë§ê²Œ RetrievalQA ì²´ì¸ ìƒì„±
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0.3),
    chain_type="stuff",  # ëª…ì‹œì ìœ¼ë¡œ ì²´ì¸ íƒ€ì… ì§€ì •
    retriever=vectorstore.as_retriever(search_kwargs=search_kwargs)
)

# ì‘ë‹µ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±
summary = f"""
ì‚¬ìš©ìëŠ” í˜„ì¬ AIì— ëŒ€í•´ '{responses['ai_knowledge']}' ìˆ˜ì¤€ì˜ ì´í•´ë„ë¥¼ ê°€ì§€ê³  ìˆê³ ,
ì£¼ëœ ëª©ì ì€ '{responses['purpose']}', ì§ì—…ì€ '{responses['job']}'ì…ë‹ˆë‹¤.
í˜„ì¬ AI ë„êµ¬ëŠ” '{responses['ai_tool_usage']}' ì •ë„ë¡œ ì‚¬ìš© ì¤‘ì´ë©°,
ê´€ì‹¬ ë¶„ì•¼ëŠ” {', '.join(responses.get('tool_interest', []))}ì…ë‹ˆë‹¤.
êµ¬ì²´ì ìœ¼ë¡œ {', '.join(responses.get('specific_purpose', []))}ì— í™œìš©í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.
ì„ í˜¸í•˜ëŠ” ë„êµ¬ ë‚œì´ë„ëŠ” '{responses.get('preferred_difficulty', 'ëª¨ë“  ë‚œì´ë„')}'ì´ë©°,
í•™ìŠµì—ì„œ ê°€ì¥ í•„ìš”í•œ ê²ƒì€ '{responses['learning_need']}'ë¼ê³  ì‘ë‹µí–ˆìŠµë‹ˆë‹¤.
ì£¼ë¡œ {', '.join(responses.get('platform', []))} í™˜ê²½ì—ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ìì˜ ë°°ê²½ ë° ê´€ì‹¬ì‚¬ì— ì í•©í•œ AI ë„êµ¬ 5ê°€ì§€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
ê° ë„êµ¬ì— ëŒ€í•´ ì´ë¦„, ì¹´í…Œê³ ë¦¬, ê¸°ëŠ¥, ì¶”ì²œ ì´ìœ ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
ì‚¬ìš©ìì˜ AI ê²½í—˜ ìˆ˜ì¤€ì— ë§ëŠ” ë„êµ¬ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš” (ì´ˆë³´ì/ì¤‘ê¸‰ì/ì „ë¬¸ê°€).
ê°€ëŠ¥í•˜ë©´ tools.txt ë¿ë§Œ ì•„ë‹ˆë¼ ai_tools_detailed_with_difficulty.jsonì— ìˆëŠ” ë„êµ¬ ì •ë³´ë„ í™œìš©í•´ì£¼ì„¸ìš”.
ì‘ë‹µì€ ëª…í™•í•˜ê²Œ êµ¬ì¡°í™”í•˜ê³ , ê° ë„êµ¬ë§ˆë‹¤ êµ¬ë¶„ì„ (---)ìœ¼ë¡œ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.
ê° ë„êµ¬ ì´ë¦„ì„ ë³¼ë“œì²´(**ë„êµ¬ëª…**)ë¡œ í‘œì‹œí•´ì£¼ì„¸ìš”.

{summary}
"""

st.markdown("### ğŸ§  ë§ì¶¤í˜• AI ë„êµ¬ ì¶”ì²œ ê²°ê³¼")
with st.spinner("ì¶”ì²œ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
    answer = qa.run(prompt)

# ì¶”ì²œ ê²°ê³¼ í‘œì‹œ
col1, col2 = st.columns([3, 2])

with col1:
    st.markdown(answer)
    
    # ì¶”ì²œëœ ë„êµ¬ ëª©ë¡ ì¶”ì¶œ
    recommended_tools = extract_recommended_tools(answer)
    
    if not recommended_tools:
        st.warning("âš ï¸ ì¶”ì²œëœ ë„êµ¬ë¥¼ ì •í™•í•˜ê²Œ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.success(f"âœ… ì‹ë³„ëœ ì¶”ì²œ ë„êµ¬: {', '.join(recommended_tools)}")

# ì‹œê°í™” ë° ë¶„ì„
with col2:
    if tools_data and recommended_tools:
        # ë ˆì´ë” ì°¨íŠ¸: ì¶”ì²œ ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë¶„ì„
        radar_fig, tool_categories = create_radar_chart(tools_data, recommended_tools)
        st.markdown("#### ğŸ“Š ì¶”ì²œ ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë¶„ì„")
        st.pyplot(radar_fig)
        
        # ì¶”ì²œ ë„êµ¬ë³„ ì„¸ë¶€ ì •ë³´
        st.markdown("#### ğŸ“‹ ì¶”ì²œ ë„êµ¬ ìƒì„¸ ì •ë³´")
        for tool_name in recommended_tools:
            tool_info = get_tool_details(tool_name, tools_data)
            if tool_info:
                with st.expander(f"{tool_name} ì„¸ë¶€ ì •ë³´", expanded=False):
                    st.markdown(f"**ì¹´í…Œê³ ë¦¬**: {tool_info.get('category', 'ì •ë³´ ì—†ìŒ')}")
                    st.markdown(f"**ë‚œì´ë„**: {tool_info.get('difficulty', 'ì¤‘ê°„')}")
                    st.markdown(f"**ì„¤ëª…**: {tool_info.get('description', 'ìƒì„¸ ì„¤ëª… ì—†ìŒ')}")

#========== ë‚œì´ë„ í•„í„° ë° ì„¸ë¶€ ì •ë³´ ==========
st.markdown("---")
st.markdown("### ğŸ” AI ë„êµ¬ ë°ì´í„°ë² ì´ìŠ¤ íƒìƒ‰")

if tools_data:
    col1, col2 = st.columns(2)
    
    with col1:
        # ë‚œì´ë„ë³„ í•„í„°ë§
        difficulty_options = ["ëª¨ë“  ë‚œì´ë„", "ì‰¬ì›€", "ì¤‘ê°„", "ì–´ë ¤ì›€"]
        selected_difficulty = st.selectbox("ë‚œì´ë„ë³„ í•„í„°ë§", difficulty_options)
    
    with col2:
        # ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§
        categories = ["ëª¨ë“  ì¹´í…Œê³ ë¦¬"] + sorted(list(set([tool.get("category", "ê¸°íƒ€") for tool in tools_data if tool.get("category")])))
        selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§", categories)
    
    # í•„í„°ë§ ì ìš©
    filtered_tools = filter_tools_by_difficulty(tools_data, selected_difficulty)
    
    if selected_category != "ëª¨ë“  ì¹´í…Œê³ ë¦¬":
        filtered_tools = [tool for tool in filtered_tools if tool.get("category") == selected_category]
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë„êµ¬ ë¶„í¬ ì‹œê°í™”
    st.markdown("### ğŸ“Š AI ë„êµ¬ ì¹´í…Œê³ ë¦¬ ë¶„í¬")
    fig = visualize_category_distribution(tools_data)
    st.pyplot(fig)
    
    # í•„í„°ë§ëœ ë„êµ¬ ë¦¬ìŠ¤íŠ¸
    st.markdown("### ğŸ“‹ í•„í„°ë§ëœ ë„êµ¬ ëª©ë¡")
    if filtered_tools:
        tool_df = pd.DataFrame([{
            "ì´ë¦„": tool.get("name", ""),
            "ì¹´í…Œê³ ë¦¬": tool.get("category", ""),
            "ë‚œì´ë„": tool.get("difficulty", "ì¤‘ê°„")
        } for tool in filtered_tools])
        
        st.dataframe(tool_df, use_container_width=True)
        
        # ë„êµ¬ ê²€ìƒ‰
        search_term = st.text_input("ğŸ” ë„êµ¬ ì´ë¦„ ê²€ìƒ‰")
        if search_term:
            filtered_df = tool_df[tool_df["ì´ë¦„"].str.contains(search_term, case=False, na=False)]
            if not filtered_df.empty:
                st.dataframe(filtered_df, use_container_width=True)
            else:
                st.info(f"'{search_term}'ì— ì¼ì¹˜í•˜ëŠ” ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

#========== ì‚¬ìš©ì í”¼ë“œë°± ==========
st.markdown("---")
st.markdown("### ğŸ“ ì¶”ì²œ í”¼ë“œë°±")
feedback_tool = st.text_input("í”¼ë“œë°±ì„ ë‚¨ê¸¸ ë„êµ¬ ì´ë¦„")

if feedback_tool:
    rating = st.slider("ë§Œì¡±ë„ í‰ê°€", 1, 5, 3)
    feedback_text = st.text_area("ìƒì„¸ í”¼ë“œë°± (ì„ íƒì‚¬í•­)")
    
    if st.button("í”¼ë“œë°± ì œì¶œ"):
        if save_user_feedback(feedback_tool, rating, feedback_text):
            st.success("í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
        else:
            st.error("í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

#========== í•™ìŠµ ë¦¬ì†ŒìŠ¤ ì¶”ì²œ ==========
st.markdown("---")
st.markdown("### ğŸ“š ì¶”ì²œ í•™ìŠµ ë¦¬ì†ŒìŠ¤")

learning_resources = {
    "ì´ˆë³´ì": [
        "AI ê¸°ì´ˆ ê°œë… ì´í•´í•˜ê¸° - ì‰¬ìš´ ì‹œì‘ ê°€ì´ë“œ",
        "ì²˜ìŒ ë§Œë‚˜ëŠ” ChatGPT - ê¸°ë³¸ ì‚¬ìš©ë²•",
        "AI ë„êµ¬ ì…ë¬¸ìë¥¼ ìœ„í•œ ë‹¨ê³„ë³„ í•™ìŠµ ê²½ë¡œ"
    ],
    "ì¤‘ê¸‰ì": [
        "ì‹¤ë¬´ì— ë°”ë¡œ ì ìš©í•˜ëŠ” AI ë„êµ¬ í™œìš©ë²•",
        "ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ AI ëª¨ë¸ í™œìš©í•˜ê¸°",
        "ì—…ë¬´ ìë™í™”ë¥¼ ìœ„í•œ AI ì›Œí¬í”Œë¡œìš° êµ¬ì¶•"
    ],
    "ì „ë¬¸ê°€": [
        "ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•",
        "AI ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•",
        "RAG(Retrieval Augmented Generation) ê³ ê¸‰ í™œìš©ë²•"
    ]
}

# ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ë¦¬ì†ŒìŠ¤ í‘œì‹œ
user_level = "ì´ˆë³´ì"
if responses.get('ai_knowledge') in ['ê¸°ë³¸ ê°œë…ì€ ì•Œê³  ìˆë‹¤', 'ì‹¤ì œë¡œ í™œìš©í•´ë³¸ ê²½í—˜ì´ ìˆë‹¤']:
    user_level = "ì¤‘ê¸‰ì"
elif responses.get('ai_knowledge') in ['AI ëª¨ë¸ì´ë‚˜ ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ ë‹¤ë¤„ë³¸ ì  ìˆë‹¤']:
    user_level = "ì „ë¬¸ê°€"

st.info(f"ğŸ“š ë‹¹ì‹ ì˜ ìˆ˜ì¤€({user_level})ì— ë§ëŠ” í•™ìŠµ ë¦¬ì†ŒìŠ¤ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤:")
for resource in learning_resources[user_level]:
    st.markdown(f"- {resource}")

st.button("ğŸ”„ ì„¤ë¬¸ ë‹¤ì‹œ í•˜ê¸°", on_click=reset_survey)
